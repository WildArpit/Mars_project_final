{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c58367ba",
   "metadata": {},
   "source": [
    "# ðŸ“„ Document Metadata Generator using OCR & NLP\n",
    "This notebook demonstrates how to extract structured metadata from documents (PDF, DOCX, TXT) using OCR (Tesseract), NLP (spaCy, NLTK), and keyword extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b41de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ“¦ Install required libraries (if not already installed)\n",
    "!pip install pytesseract pdf2image python-docx PyMuPDF spacy nltk scikit-learn pillow\n",
    "!apt-get update && apt-get install -y tesseract-ocr poppler-utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ§  Download necessary models\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ”§ Set Tesseract path (for Colab/Linux it's usually installed to /usr/bin)\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ“‚ Import required modules\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import docx\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b14232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ“„ Functions for document parsing\n",
    "\n",
    "def extract_text_from_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        return file.read()\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    pdf = fitz.open(file_path)\n",
    "    for page in pdf:\n",
    "        text += page.get_text()\n",
    "    pdf.close()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_scanned_pdf(file_path):\n",
    "    text = \"\"\n",
    "    images = convert_from_path(file_path)\n",
    "    for image in images:\n",
    "        text += pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "def extract_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    if ext == '.txt':\n",
    "        return extract_text_from_txt(file_path)\n",
    "    elif ext == '.docx':\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif ext == '.pdf':\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "        if len(text.strip()) < 100:\n",
    "            return extract_text_from_scanned_pdf(file_path)\n",
    "        return text\n",
    "    else:\n",
    "        return \"Unsupported file type.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ§  Metadata generation functions\n",
    "\n",
    "def extract_title(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if line.strip() and len(line.strip().split()) >= 3:\n",
    "            return line.strip()\n",
    "    return \"Unknown Title\"\n",
    "\n",
    "def extract_summary(text, n_sentences=3):\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) <= n_sentences:\n",
    "        return \" \".join(sentences)\n",
    "    sorted_sentences = sorted(sentences, key=lambda x: len(x), reverse=True)\n",
    "    return \" \".join(sorted_sentences[:n_sentences])\n",
    "\n",
    "def extract_keywords(text, num_keywords=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=50)\n",
    "    X = vectorizer.fit_transform([text])\n",
    "    keywords = vectorizer.get_feature_names_out()\n",
    "    return keywords[:num_keywords]\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in entities:\n",
    "            entities[ent.label_] = []\n",
    "        if ent.text not in entities[ent.label_]:\n",
    "            entities[ent.label_].append(ent.text)\n",
    "    return entities\n",
    "\n",
    "def generate_metadata(text):\n",
    "    return {\n",
    "        \"Title\": extract_title(text),\n",
    "        \"Summary\": extract_summary(text),\n",
    "        \"Keywords\": list(extract_keywords(text)),\n",
    "        \"Named Entities\": extract_named_entities(text)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# âœ… Example Run\n",
    "# Upload a file using the file upload UI in Colab\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "file_path = list(uploaded.keys())[0]\n",
    "text = extract_text(file_path)\n",
    "metadata = generate_metadata(text)\n",
    "\n",
    "print(\"ðŸ“Œ Title:\", metadata[\"Title\"])\n",
    "print(\"\\nðŸ“ Summary:\\n\", metadata[\"Summary\"])\n",
    "print(\"\\nðŸ”‘ Keywords:\", \", \".join(metadata[\"Keywords\"]))\n",
    "print(\"\\nðŸ§  Named Entities:\")\n",
    "for label, ents in metadata[\"Named Entities\"].items():\n",
    "    print(f\"{label}: {', '.join(ents)}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
